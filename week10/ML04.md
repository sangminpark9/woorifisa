# SVC는 "Support Vector Classification"의 약자로, 지지 벡터 기계(Support Vector Machine, SVM) 알고리즘을 분류 문제에 적용한 것입니다.
SVC의 주요 특징과 개념을 설명해 드리겠습니다:
1. 정의: SVC는 sklearn.svm 모듈에서 제공하는 클래스로, 분류 작업을 수행하는 SVM 모델을 구현합니다.
2. 목적: 데이터 포인트들을 가장 잘 분리하는 초평면(hyperplane)을 찾아 분류를 수행합니다.
3. 특징:
   * 이진 분류와 다중 분류 모두 가능합니다.
   * 선형 및 비선형 분류가 가능합니다.
   * 고차원 공간에서도 효과적으로 작동합니다.
4. 주요 파라미터:
   * C: 오류를 얼마나 허용할지 제어하는 정규화 파라미터입니다.
   * kernel: 선형 분리가 불가능한 경우 사용할 커널 함수를 지정합니다 (예: 'linear', 'rbf', 'poly' 등).
   * gamma: 'rbf', 'poly', 'sigmoid' 커널의 계수입니다.
5. 작동 방식:
   * 데이터 포인트들 사이의 마진(여백)을 최대화하는 결정 경계를 찾습니다.
   * 서포트 벡터라 불리는 경계에 가장 가까운 데이터 포인트들을 이용해 결정 경계를 정의합니다.
6. 장점:
   * 고차원 공간에서 효과적입니다.
   * 메모리 효율적입니다 (결정 함수에 서포트 벡터만 사용).
   * 다양한 커널 함수를 사용할 수 있어 유연합니다.
7. 단점:
   * 대규모 데이터셋에 대해 학습 시간이 오래 걸릴 수 있습니다.
   * 최적의 파라미터를 찾는 데 시간이 많이 소요될 수 있습니다.

```python
from sklearn import svm, datasets
from sklearn.model_selection import GridSearchCV

# 1. 데이터 로드
iris = datasets.load_iris()

# 2. 모델 생성
svc = svm.SVC()

# 3. 그리드 서치를 위한 파라미터 설정
parameters = {
    'C': [0.01, 0.1, 1, 10],
    'gamma': [0.01, 0.1, 1, 10]
}

# 4. GridSearchCV 객체 생성
grid_svc = GridSearchCV(svc, parameters, cv=5, n_jobs=-1)

# 5. 모델 학습
grid_svc.fit(iris.data, iris.target)

# 6. 결과 확인
print("Best parameters:", grid_svc.best_params_)
print("Best score:", grid_svc.best_score_)
```


# Confusion matrix
```python
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
# 실제값과 예측값을 임시로 구성

y_true = [1, 0, 1, 1, 0, 1]  # y_test
y_pred = [0, 0, 1, 1, 0, 1]  # 모델이 예측한 결과  model.predict(X_test)라고 가정

confusion_matrix(y_true, y_pred)
```

```
array([[2, 0],    True Negative       False Positive
       [1, 3]])   False Negative      True Positive
```

