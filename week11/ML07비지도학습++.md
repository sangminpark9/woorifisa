# 차원의 저주와 주성분 분석 (PCA)

## 차원의 저주

차원의 저주는 고차원 공간에서 발생하는 현상으로, 데이터 분석과 기계 학습 분야에서 중요한 개념입니다.

### 정의
- 데이터의 차원이 증가함에 따라 발생하는 다양한 문제들을 총칭합니다.

### 주요 특징
- **데이터 희소성**: 차원이 증가할수록 데이터 포인트 간 거리가 멀어집니다.
- **모델 복잡성 증가**: 고차원에서는 더 복잡한 모델이 필요합니다.
- **계산 비용 증가**: 차원이 높아질수록 연산량이 급격히 증가합니다.

### 영향
- 데이터 분석의 어려움 증가
- 기계 학습 알고리즘의 성능 저하
- 과적합(overfitting) 위험 증가

### 대응 방법
- 차원 축소 기법 사용 (예: PCA, t-SNE)
- 특성 선택(feature selection)
- 정규화(regularization) 기법 적용

## 주성분 분석 (PCA)

주성분 분석(PCA, Principal Component Analysis)은 다차원 데이터를 분석하는 중요한 통계적 기법입니다.

### 목적
- 고차원 데이터의 차원을 줄이면서 가능한 한 많은 정보를 보존하는 것입니다.

### 작동 원리
- 데이터의 분산을 최대한 보존하는 새로운 축(주성분)을 찾아 데이터를 변환합니다.

### 주요 특징
- 데이터의 차원 축소
- 데이터 압축
- 노이즈 제거
- 변수 간 상관관계 제거

### 응용 분야
- 이미지 처리
- 유전체 데이터 분석
- 금융 데이터 분석
- 패턴 인식

## 이미지 PCA 예제

PCA는 고차원 데이터를 저차원으로 축소하는 데 유용한 기법으로, 이미지 처리에서도 널리 사용됩니다.

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.datasets import load_digits

# 예제로 사용할 숫자 이미지 데이터 로드
digits = load_digits()
X = digits.data
y = digits.target

# PCA 객체 생성 (주성분 개수를 20으로 설정)
pca = PCA(n_components=20)

# PCA 적용
X_pca = pca.fit_transform(X)

# 원본 이미지와 재구성된 이미지 시각화
def plot_digits(instances, images_per_row=5, **options):
    size = 8
    images_per_row = min(len(instances), images_per_row)
    images = [instance.reshape(size, size) for instance in instances]
    n_rows = (len(instances) - 1) // images_per_row + 1
    row_images = []
    n_empty = n_rows * images_per_row - len(instances)
    images.append(np.zeros((size, size * n_empty)))
    for row in range(n_rows):
        rimages = images[row * images_per_row : (row + 1) * images_per_row]
        row_images.append(np.concatenate(rimages, axis=1))
    image = np.concatenate(row_images, axis=0)
    plt.imshow(image, cmap = plt.cm.binary, **options)
    plt.axis("off")

plt.figure(figsize=(10, 4))
plt.subplot(121)
plot_digits(X[:5])
plt.title("Original Images")

X_recovered = pca.inverse_transform(X_pca)
plt.subplot(122)
plot_digits(X_recovered[:5])
plt.title("Reconstructed Images")
plt.show()

# 설명력 시각화
explained_variance_ratio = pca.explained_variance_ratio_
cumulative_explained_variance_ratio = np.cumsum(explained_variance_ratio)

plt.figure(figsize=(10, 5))
plt.plot(range(1, len(cumulative_explained_variance_ratio) + 1), cumulative_explained_variance_ratio, 'bo-')
plt.xlabel('Number of Components')
plt.ylabel('Cumulative Explained Variance Ratio')
plt.title('Explained Variance Ratio by Number of Components')
plt.grid(True)
plt.show()

print(f"Explained variance ratio with 20 components: {cumulative_explained_variance_ratio[-1]:.4f}")
```

이 코드는 MNIST 데이터셋의 숫자 이미지에 PCA를 적용하고, 원본 이미지와 재구성된 이미지를 비교하며, 주성분 수에 따른 설명된 분산 비율을 시각화합니다.
