# KPT 회고
1. Keep
   - 기술세미나 어느 정도 가닥이 잡힌 것 같다.
2. Problem
   - ELK, bulk를 까먹었었닿ㅎ
   - HTTP 통신에 대해 다 꺼먹고 REST API를 설명하려 하니 잘못 된 것
3. Try
   - 한 주는 웹에 대해서 공부를 하자

---
# Aggs(집계함수) 내부 동작, threshold

```
# cardinality - 지정한 필드가 가진 고유한 값의 개수를 계산해 반환한다.
# HyperLogLog++ 알고리즘 을 사용해 추정한 근사값이다.
# 1. 지정된 threshold 기준으로 각 document을 해싱한다. (규격화된 난수를 만듬
# 2.앞의 n자리 정도만 겹치는 값들을 '같은 값'이라고 어림짐작합니다. 

# 3. 그 결과를 돌려주게 된다.
# 확실한 cardinality를 보장받는 방법 -> 전체 document의 수만큼 threshold를 줍니다. 
# 대용량분산처리 프레임워크에서 고유값을 찾으실 때는 나온 값 그대로를 믿지 마세요. GET kibana_sample_data_ecommerce/_search
```

## HyperLogLog++ 알고리즘의 과정:
1. **해싱**:
   * 모든 문서(혹은 데이터)의 지정된 필드를 해싱합니다. 해싱은 데이터를 고정된 크기의 난수(또는 해시값)로 변환하는 과정입니다. 이 단계에서는 필드의 값을 특정 크기의 숫자로 바꾸게 되는데, 이 숫자는 사실상 무작위처럼 보이지만 같은 값은 항상 같은 해시값으로 변환됩니다.
2. **비교 및 분류**:
   * 해시된 값을 기준으로 비교합니다. 해시값의 앞 n자리 정도만을 살펴보고, 이 n자리가 동일한 값들은 같은 값이라고 어림짐작합니다. 예를 들어, 해시값의 앞 4자리가 "0000"인 모든 값들을 같은 그룹으로 묶습니다. 이 단계에서 전체 값을 하나하나 정확히 계산하지 않고, 일부만 비교함으로써 계산을 단순화합니다.
3. **결과 반환**:
   * 위의 비교 및 분류 과정으로 도출된 결과를 바탕으로 고유한 값의 개수를 근사치로 계산해 반환합니다. 이 방법은 데이터를 정확하게 계산하는 것이 아니라, **대략적인 개수를 매우 빠르게** 추정하는 데 중점을 둡니다.


# agg 집계함수 활용
```javascript
// 시간 구간은 calendar_interval 이라는 파라미터로 나눌 수 있습니다. 
// 1m - mimute 
// 1h - hour
// 1d - day
// 1M - month
// 1q - quarter (분기)
// 1y - year 

GET kibana_sample_data_flights/_search
{
  "size": 0,
  "aggs": {
    "일일 비행기 평균 금액": {
      "date_histogram": {
        "field": "timestamp",
        "fixed_interval": "1d"
      },
      "aggs": {
        "평균 비행기 금액": {
          "avg": {
            "field": "AvgTicketPrice"
          }
        }
      }
    }
  }
}

GET kibana_sample_data_flights/_search
{
  "size": 0,
  "aggs": {
    "일일 비행기 평균 금액": {
      "date_range": {
        "field": "timestamp",
        "ranges": [
          {"to": "now-2d/d"},
          {"from": "now-2d/d",
            "to": "now-1d/d"
          },
          {"from": "now-1d/d"
          }
          ]
      },
      "aggs": {
        "평균 비행기 금액": {
          "avg": {
            "field": "AvgTicketPrice"
          }
        }
      }
    }
  }
}




—--
###
# terms 집계는 각 샤드에서 size 개수만큼 term을 뽑아 빈도수를 셉니다. 
# 버킷을 최대 몇 개까지 생성할 것인지를 size로 지정합니다.

GET kibana_sample_data_logs/_search
{
  "size": 0,
  "query": {
    "match_all": {}
},
"aggs": {
    "가장많이접속한 ip주소": {
      "terms": {
        "field": "host.keyword",
        "size": 1000
      }
    }
  }
}

GET kibana_sample_data_logs/_search
{
  "size": 0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "composite-aggs": {
      "composite": {
        "size": 100, 
        "sources": [
          {
            "terms-aggs": {
              "terms": {
                "field": "host.keyword"
              }
            }
          },
          {
            "date-histogram-aggs": {
              "date_histogram": {
                "field": "@timestamp",
                "calendar_interval": "day", // unixtime을
                "format": "yyyy-MM-dd"
              }
            }
          }
        ]
      }
    }
  }
}

GET kibana_sample_data_logs/_search
{
  "size": 0,
  "query": {
    "match_all": {}
  },
  "aggs": {
    "composite-aggs": {
      "composite": {
        "size": 100, 
          "sources": [
          {
            "terms-aggs": {
              "terms": {
                "field": "host.keyword"
              }
            }
          },
                    {
            "date-histogram-aggs": {
              "date_histogram": {
                "field": "@timestamp",
                "calendar_interval": "day"
              }
            }
          }
        ],
        "after": {
          "terms-aggs": "cdn.elastic-elastic-elastic.org",
          "date-histogram-aggs": 1675209600000
        }
      }
    }
  }
}

```


# agg, 문자열은 keyword로만 검색 가능
```javascript
GET bank/_search
{
  "aggs": {
    "위치별 은행 갯수": {
      "value_count": {
        "field": "location.keyword"
      }
    }
  }
}
```

#  각 은행별로 총 고객 수와 고객 수 평균을 모두 집계합니다.

```javascript
GET bank/_search
{
  "size": 0,
  "aggs": {
    "은행별 지점 개수수": {
      "terms": {
        "field": "bank.keyword"
      }
    }
  }
}
```

# Kibana
### Analytics는 시각화 연관
1. 디스커버 : 데이터를 도큐먼트 단위로 탐색
2. 시각화 : 다양한 그래프 타입
3. 대시보드 : 그래프, 지도 등을 한 곳에서 확인
4. 캔버스 : 그래프와 이미지 등을 프레젠테이션 슬라이드처럼 구성

![image](https://github.com/user-attachments/
assets/69b8d5ab-1ffc-4726-90ac-5c5ce1e987b6)

 <img width="1163" alt="image" src="https://github.com/user-attachments/assets/91138718-2ce4-48f7-9c31-c8c1c8935a27">

<img width="729" alt="image" src="https://github.com/user-attachments/assets/e2338c61-58bf-4a02-88a8-6aa046883cbd">
